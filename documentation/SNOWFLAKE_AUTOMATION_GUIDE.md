# üç∑ Les Caves d'Albert - Guide d'Automatisation Snowflake

## üìã Table des Mati√®res
1. [Vue d'ensemble](#vue-densemble)
2. [Architecture des Tasks et Streams](#architecture-des-tasks-et-streams)
3. [Sch√©mas de donn√©es](#sch√©mas-de-donn√©es)
4. [Guide d'impl√©mentation](#guide-dimpl√©mentation)
5. [Monitoring et maintenance](#monitoring-et-maintenance)
6. [Cas d'usage analytiques](#cas-dusage-analytiques)

---

## üéØ Vue d'ensemble

### Architecture en 3 couches

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  KAFKA PRODUCER ‚Üí REDPANDA ‚Üí CONSUMER ‚Üí SNOWFLAKE          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LAYER 1: RAW (Bronze)                                      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ RAW_EVENTS_STREAM (donn√©es brutes JSON)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì STREAMS + TASKS
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LAYER 2: STAGING (Silver)                                  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ STG_ORDERS (commandes transform√©es)                    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ STG_INVENTORY_ADJUSTMENTS (ajustements transform√©s)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì STREAMS + TASKS
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LAYER 3: PRODUCTION (Gold)                                 ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ ORDERS (commandes finales)                             ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ INVENTORY_CURRENT (inventaire temps r√©el)              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ INVENTORY_HISTORY (historique complet)                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîÑ Architecture des Tasks et Streams

### DAG (Directed Acyclic Graph) des Tasks

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  TASK_RAW_TO_STAGING_ORDERS                  ‚îÇ
‚îÇ  ‚è±Ô∏è  Schedule: 1 MINUTE                      ‚îÇ
‚îÇ  üìä Source: STREAM_RAW_ORDERS                ‚îÇ
‚îÇ  üéØ Target: STAGING.STG_ORDERS               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  TASK_STAGING_TO_PROD_ORDERS                 ‚îÇ
‚îÇ  üîó Trigger: AFTER parent task               ‚îÇ
‚îÇ  üìä Source: STREAM_STG_ORDERS                ‚îÇ
‚îÇ  üéØ Target: PRODUCTION.ORDERS                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  TASK_RAW_TO_STAGING_INVENTORY               ‚îÇ
‚îÇ  ‚è±Ô∏è  Schedule: 1 MINUTE                      ‚îÇ
‚îÇ  üìä Source: STREAM_RAW_INVENTORY             ‚îÇ
‚îÇ  üéØ Target: STAGING.STG_INVENTORY_ADJ        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  TASK_STAGING_TO_PROD_INVENTORY_HISTORY      ‚îÇ
‚îÇ  üîó Trigger: AFTER parent task               ‚îÇ
‚îÇ  üìä Source: STREAM_STG_INVENTORY             ‚îÇ
‚îÇ  üéØ Target: PRODUCTION.INVENTORY_HISTORY     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  TASK_STAGING_TO_PROD_INVENTORY_CURRENT      ‚îÇ
‚îÇ  üîó Trigger: AFTER parent task               ‚îÇ
‚îÇ  üìä Source: STREAM_STG_INVENTORY             ‚îÇ
‚îÇ  üéØ Target: PRODUCTION.INVENTORY_CURRENT     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Types de Streams

| Stream | Table Source | Mode | Description |
|--------|-------------|------|-------------|
| `STREAM_RAW_ORDERS` | `RAW_EVENTS_STREAM` | APPEND_ONLY | Capture uniquement les nouveaux √©v√©nements ORDER_CREATED |
| `STREAM_RAW_INVENTORY` | `RAW_EVENTS_STREAM` | APPEND_ONLY | Capture uniquement les nouveaux √©v√©nements INVENTORY_ADJUSTED |
| `STREAM_STG_ORDERS` | `STAGING.STG_ORDERS` | STANDARD | Capture INSERT/UPDATE/DELETE pour CDC complet |
| `STREAM_STG_INVENTORY` | `STAGING.STG_INVENTORY_ADJ` | STANDARD | Capture INSERT/UPDATE/DELETE pour CDC complet |

---

## üìä Sch√©mas de donn√©es

### RAW Layer (Bronze)

```sql
RAW_EVENTS_STREAM
‚îú‚îÄ‚îÄ EVENT_ID (VARCHAR) - UUID unique
‚îú‚îÄ‚îÄ EVENT_TYPE (VARCHAR) - 'ORDER_CREATED' ou 'INVENTORY_ADJUSTED'
‚îú‚îÄ‚îÄ EVENT_TIMESTAMP (TIMESTAMP_NTZ) - Timestamp de l'√©v√©nement
‚îú‚îÄ‚îÄ PRODUCT_ID (VARCHAR) - ID produit (ex: PROD-001)
‚îú‚îÄ‚îÄ CUSTOMER_ID (VARCHAR) - ID client (ex: CUST-12345)
‚îú‚îÄ‚îÄ EVENT_DATA (VARIANT) - JSON contenant toutes les donn√©es
‚îî‚îÄ‚îÄ INGESTION_TIMESTAMP (TIMESTAMP_NTZ) - Timestamp d'ingestion Kafka
```

**Exemple EVENT_DATA pour ORDER_CREATED:**
```json
{
  "order_id": "ORD-20251019-123456",
  "customer_id": "CUST-67890",
  "product_name": "üç∑ Ch√¢teau Margaux 2015",
  "product_category": "Rouge",
  "quantity": 2,
  "unit_price": 450.00,
  "total_amount": 900.00,
  "payment_method": "CARTE_BANCAIRE",
  "shipping_address": "123 Rue de la Paix, 75002 Paris"
}
```

**Exemple EVENT_DATA pour INVENTORY_ADJUSTED:**
```json
{
  "adjustment_id": "ADJ-20251019-789012",
  "product_name": "ü•Ç Mo√´t & Chandon Brut Imperial",
  "product_category": "Effervescent",
  "adjustment_type": "RESTOCK",
  "quantity_change": 50,
  "new_stock_level": 250,
  "reason": "R√©approvisionnement hebdomadaire",
  "warehouse_location": "Entrep√¥t Paris Nord"
}
```

### STAGING Layer (Silver)

Tables interm√©diaires avec donn√©es extraites du JSON et nettoy√©es.

**STG_ORDERS** - Commandes pr√™tes pour la production
**STG_INVENTORY_ADJUSTMENTS** - Ajustements d'inventaire pr√™ts pour la production

### PRODUCTION Layer (Gold)

Tables finales optimis√©es pour l'analytique.

**ORDERS** - Toutes les commandes clients (MERGE avec UPDATE si m√™me ORDER_ID)
**INVENTORY_CURRENT** - √âtat actuel de l'inventaire par produit (1 ligne par produit)
**INVENTORY_HISTORY** - Historique complet de tous les ajustements (audit trail)

---

## üöÄ Guide d'impl√©mentation

### √âtape 1: Pr√©parer les sch√©mas

```sql
-- Cr√©er les sch√©mas si n√©cessaire
CREATE SCHEMA IF NOT EXISTS STAGING;
CREATE SCHEMA IF NOT EXISTS PRODUCTION;

-- V√©rifier
SHOW SCHEMAS IN DATABASE CAVES_ALBERT_DB;
```

### √âtape 2: Ex√©cuter le script principal

```sql
-- Ex√©cuter snowflake-tasks-streams.sql dans Snowflake
-- Cela cr√©era :
-- ‚úÖ 5 tables (2 staging + 3 production)
-- ‚úÖ 4 streams (CDC)
-- ‚úÖ 5 tasks (pipelines automatis√©s)
```

### √âtape 3: Activer les tasks

```sql
-- Les tasks sont activ√©es automatiquement dans le script
-- V√©rifier l'√©tat :
SHOW TASKS IN SCHEMA RAW_DATA;

-- R√©sultat attendu :
-- STATE = 'started' pour toutes les tasks
```

### √âtape 4: V√©rifier le flux de donn√©es

```sql
-- 1. V√©rifier les streams
SELECT 'STREAM_RAW_ORDERS' AS STREAM, 
       SYSTEM$STREAM_HAS_DATA('STREAM_RAW_ORDERS') AS HAS_DATA,
       (SELECT COUNT(*) FROM STREAM_RAW_ORDERS) AS ROW_COUNT;

-- 2. Voir les donn√©es qui transitent
SELECT * FROM STREAM_RAW_ORDERS LIMIT 10;

-- 3. V√©rifier l'historique des tasks
SELECT
    NAME,
    STATE,
    SCHEDULED_TIME,
    COMPLETED_TIME,
    DATEDIFF('second', SCHEDULED_TIME, COMPLETED_TIME) AS DURATION_SEC
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY())
WHERE NAME LIKE 'TASK_%'
ORDER BY SCHEDULED_TIME DESC
LIMIT 10;
```

---

## üìà Monitoring et maintenance

### Dashboard de monitoring

```sql
-- Vue d'ensemble du pipeline
CREATE OR REPLACE VIEW MONITORING.PIPELINE_HEALTH AS
SELECT
    'RAW_EVENTS_STREAM' AS TABLE_NAME,
    COUNT(*) AS ROW_COUNT,
    MAX(INGESTION_TIMESTAMP) AS LAST_INGESTION
FROM RAW_EVENTS_STREAM
UNION ALL
SELECT
    'STG_ORDERS',
    COUNT(*),
    MAX(INGESTION_TIMESTAMP)
FROM STAGING.STG_ORDERS
UNION ALL
SELECT
    'STG_INVENTORY_ADJUSTMENTS',
    COUNT(*),
    MAX(INGESTION_TIMESTAMP)
FROM STAGING.STG_INVENTORY_ADJUSTMENTS
UNION ALL
SELECT
    'ORDERS',
    COUNT(*),
    MAX(UPDATED_AT)
FROM PRODUCTION.ORDERS
UNION ALL
SELECT
    'INVENTORY_CURRENT',
    COUNT(*),
    MAX(UPDATED_AT)
FROM PRODUCTION.INVENTORY_CURRENT
UNION ALL
SELECT
    'INVENTORY_HISTORY',
    COUNT(*),
    MAX(CREATED_AT)
FROM PRODUCTION.INVENTORY_HISTORY;
```

### Alertes importantes

```sql
-- 1. Tasks en erreur
SELECT
    NAME,
    STATE,
    ERROR_CODE,
    ERROR_MESSAGE,
    SCHEDULED_TIME
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY())
WHERE STATE = 'FAILED'
    AND SCHEDULED_TIME > DATEADD('hour', -1, CURRENT_TIMESTAMP())
ORDER BY SCHEDULED_TIME DESC;

-- 2. Latence du pipeline (plus de 5 minutes)
SELECT
    MAX(INGESTION_TIMESTAMP) AS LAST_RAW_INGESTION,
    MAX(UPDATED_AT) AS LAST_PROD_UPDATE,
    DATEDIFF('minute', MAX(UPDATED_AT), CURRENT_TIMESTAMP()) AS LATENCY_MINUTES
FROM PRODUCTION.ORDERS;

-- 3. Produits en rupture de stock
SELECT
    PRODUCT_ID,
    PRODUCT_NAME,
    PRODUCT_CATEGORY,
    CURRENT_STOCK_LEVEL,
    LAST_ADJUSTMENT_TIMESTAMP
FROM PRODUCTION.INVENTORY_CURRENT
WHERE CURRENT_STOCK_LEVEL <= 0
ORDER BY LAST_ADJUSTMENT_TIMESTAMP DESC;
```

### Maintenance r√©guli√®re

```sql
-- 1. Nettoyer les anciennes donn√©es RAW (> 30 jours)
DELETE FROM RAW_EVENTS_STREAM
WHERE INGESTION_TIMESTAMP < DATEADD('day', -30, CURRENT_TIMESTAMP());

-- 2. Nettoyer les donn√©es STAGING (> 7 jours)
DELETE FROM STAGING.STG_ORDERS
WHERE INGESTION_TIMESTAMP < DATEADD('day', -7, CURRENT_TIMESTAMP());

DELETE FROM STAGING.STG_INVENTORY_ADJUSTMENTS
WHERE INGESTION_TIMESTAMP < DATEADD('day', -7, CURRENT_TIMESTAMP());

-- 3. Archiver l'historique ancien (> 1 an) dans une table d'archive
CREATE TABLE IF NOT EXISTS PRODUCTION.INVENTORY_HISTORY_ARCHIVE 
    LIKE PRODUCTION.INVENTORY_HISTORY;

INSERT INTO PRODUCTION.INVENTORY_HISTORY_ARCHIVE
SELECT * FROM PRODUCTION.INVENTORY_HISTORY
WHERE ADJUSTMENT_DATE < DATEADD('year', -1, CURRENT_DATE());

DELETE FROM PRODUCTION.INVENTORY_HISTORY
WHERE ADJUSTMENT_DATE < DATEADD('year', -1, CURRENT_DATE());
```

---

## üìä Cas d'usage analytiques

### 1. Dashboard KPI temps r√©el

```sql
-- M√©triques cl√©s du jour
SELECT
    COUNT(*) AS ORDERS_TODAY,
    SUM(TOTAL_AMOUNT) AS REVENUE_TODAY,
    AVG(TOTAL_AMOUNT) AS AVG_ORDER_VALUE,
    COUNT(DISTINCT CUSTOMER_ID) AS UNIQUE_CUSTOMERS
FROM PRODUCTION.ORDERS
WHERE ORDER_DATE = CURRENT_DATE();
```

### 2. Analyse des ventes par cat√©gorie

```sql
SELECT
    PRODUCT_CATEGORY,
    COUNT(*) AS ORDER_COUNT,
    SUM(QUANTITY) AS UNITS_SOLD,
    SUM(TOTAL_AMOUNT) AS TOTAL_REVENUE,
    AVG(UNIT_PRICE) AS AVG_PRICE
FROM PRODUCTION.ORDERS
WHERE ORDER_DATE >= DATEADD('day', -30, CURRENT_DATE())
GROUP BY PRODUCT_CATEGORY
ORDER BY TOTAL_REVENUE DESC;
```

### 3. Top clients (fid√©lit√©)

```sql
SELECT
    CUSTOMER_ID,
    COUNT(*) AS ORDER_COUNT,
    SUM(TOTAL_AMOUNT) AS LIFETIME_VALUE,
    AVG(TOTAL_AMOUNT) AS AVG_ORDER_VALUE,
    MAX(ORDER_DATE) AS LAST_ORDER_DATE,
    DATEDIFF('day', MAX(ORDER_DATE), CURRENT_DATE()) AS DAYS_SINCE_LAST_ORDER
FROM PRODUCTION.ORDERS
GROUP BY CUSTOMER_ID
HAVING ORDER_COUNT >= 5
ORDER BY LIFETIME_VALUE DESC
LIMIT 20;
```

### 4. Pr√©vision de rupture de stock

```sql
-- Calculer le taux de vente moyen et estimer les jours de stock restants
WITH daily_sales AS (
    SELECT
        PRODUCT_ID,
        PRODUCT_NAME,
        PRODUCT_CATEGORY,
        AVG(daily_quantity) AS AVG_DAILY_SALES
    FROM (
        SELECT
            PRODUCT_ID,
            PRODUCT_NAME,
            PRODUCT_CATEGORY,
            ORDER_DATE,
            SUM(QUANTITY) AS daily_quantity
        FROM PRODUCTION.ORDERS
        WHERE ORDER_DATE >= DATEADD('day', -30, CURRENT_DATE())
        GROUP BY PRODUCT_ID, PRODUCT_NAME, PRODUCT_CATEGORY, ORDER_DATE
    )
    GROUP BY PRODUCT_ID, PRODUCT_NAME, PRODUCT_CATEGORY
)
SELECT
    i.PRODUCT_ID,
    i.PRODUCT_NAME,
    i.PRODUCT_CATEGORY,
    i.CURRENT_STOCK_LEVEL,
    s.AVG_DAILY_SALES,
    CASE
        WHEN s.AVG_DAILY_SALES > 0 THEN
            ROUND(i.CURRENT_STOCK_LEVEL / s.AVG_DAILY_SALES, 1)
        ELSE NULL
    END AS DAYS_OF_STOCK_REMAINING,
    CASE
        WHEN i.CURRENT_STOCK_LEVEL / s.AVG_DAILY_SALES < 7 THEN 'üî¥ URGENT'
        WHEN i.CURRENT_STOCK_LEVEL / s.AVG_DAILY_SALES < 14 THEN 'üü† ATTENTION'
        ELSE 'üü¢ OK'
    END AS STOCK_STATUS
FROM PRODUCTION.INVENTORY_CURRENT i
JOIN daily_sales s ON i.PRODUCT_ID = s.PRODUCT_ID
WHERE s.AVG_DAILY_SALES > 0
ORDER BY DAYS_OF_STOCK_REMAINING ASC;
```

### 5. Analyse de la saisonnalit√©

```sql
SELECT
    DAYNAME(ORDER_DATE) AS DAY_OF_WEEK,
    HOUR(ORDER_TIMESTAMP) AS HOUR_OF_DAY,
    COUNT(*) AS ORDER_COUNT,
    SUM(TOTAL_AMOUNT) AS REVENUE
FROM PRODUCTION.ORDERS
WHERE ORDER_DATE >= DATEADD('day', -90, CURRENT_DATE())
GROUP BY DAYNAME(ORDER_DATE), HOUR(ORDER_TIMESTAMP)
ORDER BY ORDER_COUNT DESC;
```

---

## üéØ Avantages de cette architecture

### ‚úÖ Temps r√©el
- Les tasks s'ex√©cutent toutes les 1 minute
- Latence totale < 2-3 minutes de bout en bout
- Donn√©es disponibles pour l'analytique quasi instantan√©ment

### ‚úÖ Co√ªt optimis√©
- Les tasks ne s'ex√©cutent que si des donn√©es sont pr√©sentes (`WHEN SYSTEM$STREAM_HAS_DATA()`)
- Pas de traitement inutile = pas de cr√©dits Snowflake gaspill√©s
- Warehouse se suspend automatiquement entre les ex√©cutions

### ‚úÖ Fiabilit√©
- CDC (Change Data Capture) natif avec les streams
- Garantie de traitement exactement une fois (exactly-once)
- Tra√ßabilit√© compl√®te avec les timestamps d'ingestion

### ‚úÖ Scalabilit√©
- Architecture modulaire (RAW ‚Üí STAGING ‚Üí PROD)
- Facile d'ajouter de nouveaux types d'√©v√©nements
- Support de millions d'√©v√©nements par jour

### ‚úÖ Maintenabilit√©
- SQL pur, pas de code externe
- Monitoring int√©gr√© avec `TASK_HISTORY()`
- Facile √† d√©bugger et √† modifier

---

## üîß D√©pannage

### Probl√®me : Les tasks ne s'ex√©cutent pas

```sql
-- 1. V√©rifier que les tasks sont bien actives
SHOW TASKS;

-- 2. Activer manuellement si n√©cessaire
ALTER TASK TASK_RAW_TO_STAGING_ORDERS RESUME;

-- 3. Ex√©cuter manuellement pour tester
EXECUTE TASK TASK_RAW_TO_STAGING_ORDERS;
```

### Probl√®me : Les streams sont vides

```sql
-- V√©rifier que des donn√©es arrivent dans RAW
SELECT COUNT(*) FROM RAW_EVENTS_STREAM
WHERE INGESTION_TIMESTAMP > DATEADD('minute', -5, CURRENT_TIMESTAMP());

-- V√©rifier que le consumer Kafka fonctionne
-- (voir les logs Docker du container consumer)
```

### Probl√®me : Erreurs dans les tasks

```sql
-- Voir les erreurs d√©taill√©es
SELECT
    NAME,
    ERROR_CODE,
    ERROR_MESSAGE,
    QUERY_TEXT
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY())
WHERE STATE = 'FAILED'
ORDER BY SCHEDULED_TIME DESC
LIMIT 5;
```

---

## üìö Ressources

- [Snowflake Streams Documentation](https://docs.snowflake.com/en/user-guide/streams-intro)
- [Snowflake Tasks Documentation](https://docs.snowflake.com/en/user-guide/tasks-intro)
- [CDC with Streams](https://docs.snowflake.com/en/user-guide/streams-cdc)
- [Task DAGs](https://docs.snowflake.com/en/user-guide/tasks-intro#task-graphs)

---

**üç∑ Bon traitement de donn√©es en temps r√©el avec Les Caves d'Albert !**
